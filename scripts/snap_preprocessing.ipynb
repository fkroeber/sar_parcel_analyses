{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Priority\n",
    "* in processing chains add the relative orbit identifier to be able to extract it later on\n",
    "* check if field border pixels were excluded in subsequent analyses\n",
    "\n",
    "# To-Do & Future improvements\n",
    "* corrects for thermal noise\n",
    "    + either apply thermal noise correction & substract from original\n",
    "    + or crop noise manually from LUT\n",
    "    + or for simplicity assuming that contribution is negligible\n",
    "    + testing multiple applications of thermal noise removal on images with prior addition of x to avoid clipping of values to 0\n",
    "* polarimetric decomposition\n",
    "* for GRD: compare & cross-validate with GRD product as created/provided by ESA\n",
    "\n",
    "# Technical improvements\n",
    "* install geopandas in pyton 3.6 (snap venv)\n",
    "\n",
    "# Questions\n",
    "* Is TOPSAR-Split required only to subset the scene or for all analyses to apply orbit files specifically to certain parts of the image?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'en_US.UTF-8'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set locale to make matplotlib import work properly\n",
    "import locale\n",
    "locale.setlocale(locale.LC_ALL, 'en_US.UTF-8')\n",
    "\n",
    "# common imports\n",
    "import glob\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import time\n",
    "import zipfile\n",
    "\n",
    "# establish connection to SNAP & import corresponding libraries\n",
    "sys.path.append('C:\\\\Users\\\\felix\\\\.virtualenvs\\\\snap\\\\Lib')\n",
    "import snappy\n",
    "import jpy\n",
    "\n",
    "# change some notebook settings\n",
    "pd.options.display.max_colwidth = 80\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define relevant paths\n",
    "s1_data_path = \"D://Adv_Rs_project/01_data_raw/s1_slc\"\n",
    "python_kernel = \"C://Users/felix/.virtualenvs/snap/Scripts/python.exe\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define help function to retrieve info for operators\n",
    "def snap_help(*operator):\n",
    "    print(subprocess.Popen(['gpt', '-h', *operator], stdout=subprocess.PIPE, universal_newlines=True).communicate()[0])\n",
    "\n",
    "# demonstration of help function\n",
    "# snap_help(\"Terrain-Correction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read & Reorganise scenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: The timedelta between scenes is not equal, 1 scene pair is more than 6 days apart.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Satellite</th>\n",
       "      <th>Absolute Orbit</th>\n",
       "      <th>Relative Orbit</th>\n",
       "      <th>Time</th>\n",
       "      <th>Filename</th>\n",
       "      <th>SLC Pairs</th>\n",
       "      <th>Pair Timedelta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S1B</td>\n",
       "      <td>026320</td>\n",
       "      <td>44</td>\n",
       "      <td>2021-04-04 16:58:29</td>\n",
       "      <td>S1B_IW_SLC__1SDV_20210404T165829_20210404T165857_026320_032437_1DA7.zip</td>\n",
       "      <td>(S1B_IW_SLC__1SDV_20210404T165829_20210404T165857_026320_032437_1DA7.zip, S1...</td>\n",
       "      <td>6 days 00:00:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S1A</td>\n",
       "      <td>037391</td>\n",
       "      <td>44</td>\n",
       "      <td>2021-04-10 16:59:13</td>\n",
       "      <td>S1A_IW_SLC__1SDV_20210410T165913_20210410T165940_037391_046811_38EF.zip</td>\n",
       "      <td>(S1A_IW_SLC__1SDV_20210410T165913_20210410T165940_037391_046811_38EF.zip, S1...</td>\n",
       "      <td>5 days 23:59:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S1B</td>\n",
       "      <td>026495</td>\n",
       "      <td>44</td>\n",
       "      <td>2021-04-16 16:58:29</td>\n",
       "      <td>S1B_IW_SLC__1SDV_20210416T165829_20210416T165857_026495_0329CA_9CB3.zip</td>\n",
       "      <td>(S1B_IW_SLC__1SDV_20210416T165829_20210416T165857_026495_0329CA_9CB3.zip, S1...</td>\n",
       "      <td>6 days 00:00:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S1A</td>\n",
       "      <td>037566</td>\n",
       "      <td>44</td>\n",
       "      <td>2021-04-22 16:59:13</td>\n",
       "      <td>S1A_IW_SLC__1SDV_20210422T165913_20210422T165940_037566_046E25_93D0.zip</td>\n",
       "      <td>(S1A_IW_SLC__1SDV_20210422T165913_20210422T165940_037566_046E25_93D0.zip, S1...</td>\n",
       "      <td>5 days 23:59:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S1B</td>\n",
       "      <td>026670</td>\n",
       "      <td>44</td>\n",
       "      <td>2021-04-28 16:58:30</td>\n",
       "      <td>S1B_IW_SLC__1SDV_20210428T165830_20210428T165857_026670_032F67_4852.zip</td>\n",
       "      <td>(S1B_IW_SLC__1SDV_20210428T165830_20210428T165857_026670_032F67_4852.zip, S1...</td>\n",
       "      <td>6 days 00:00:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>S1B</td>\n",
       "      <td>028996</td>\n",
       "      <td>95</td>\n",
       "      <td>2021-10-05 05:17:43</td>\n",
       "      <td>S1B_IW_SLC__1SDV_20211005T051743_20211005T051810_028996_0375C9_067D.zip</td>\n",
       "      <td>(S1B_IW_SLC__1SDV_20211005T051743_20211005T051810_028996_0375C9_067D.zip, S1...</td>\n",
       "      <td>6 days 00:00:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>S1A</td>\n",
       "      <td>040067</td>\n",
       "      <td>95</td>\n",
       "      <td>2021-10-11 05:18:25</td>\n",
       "      <td>S1A_IW_SLC__1SDV_20211011T051825_20211011T051853_040067_04BE64_5A70.zip</td>\n",
       "      <td>(S1A_IW_SLC__1SDV_20211011T051825_20211011T051853_040067_04BE64_5A70.zip, S1...</td>\n",
       "      <td>5 days 23:59:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>S1B</td>\n",
       "      <td>029171</td>\n",
       "      <td>95</td>\n",
       "      <td>2021-10-17 05:17:43</td>\n",
       "      <td>S1B_IW_SLC__1SDV_20211017T051743_20211017T051810_029171_037B32_8EF0.zip</td>\n",
       "      <td>(S1B_IW_SLC__1SDV_20211017T051743_20211017T051810_029171_037B32_8EF0.zip, S1...</td>\n",
       "      <td>6 days 00:00:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>S1A</td>\n",
       "      <td>040242</td>\n",
       "      <td>95</td>\n",
       "      <td>2021-10-23 05:18:25</td>\n",
       "      <td>S1A_IW_SLC__1SDV_20211023T051825_20211023T051853_040242_04C47E_CF1D.zip</td>\n",
       "      <td>(S1A_IW_SLC__1SDV_20211023T051825_20211023T051853_040242_04C47E_CF1D.zip, S1...</td>\n",
       "      <td>5 days 23:59:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>S1B</td>\n",
       "      <td>029346</td>\n",
       "      <td>95</td>\n",
       "      <td>2021-10-29 05:17:43</td>\n",
       "      <td>S1B_IW_SLC__1SDV_20211029T051743_20211029T051810_029346_038095_6DF0.zip</td>\n",
       "      <td>(S1B_IW_SLC__1SDV_20211029T051743_20211029T051810_029346_038095_6DF0.zip, nan)</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Satellite Absolute Orbit  Relative Orbit                Time  \\\n",
       "0        S1B         026320              44 2021-04-04 16:58:29   \n",
       "1        S1A         037391              44 2021-04-10 16:59:13   \n",
       "2        S1B         026495              44 2021-04-16 16:58:29   \n",
       "3        S1A         037566              44 2021-04-22 16:59:13   \n",
       "4        S1B         026670              44 2021-04-28 16:58:30   \n",
       "..       ...            ...             ...                 ...   \n",
       "65       S1B         028996              95 2021-10-05 05:17:43   \n",
       "66       S1A         040067              95 2021-10-11 05:18:25   \n",
       "67       S1B         029171              95 2021-10-17 05:17:43   \n",
       "68       S1A         040242              95 2021-10-23 05:18:25   \n",
       "69       S1B         029346              95 2021-10-29 05:17:43   \n",
       "\n",
       "                                                                   Filename  \\\n",
       "0   S1B_IW_SLC__1SDV_20210404T165829_20210404T165857_026320_032437_1DA7.zip   \n",
       "1   S1A_IW_SLC__1SDV_20210410T165913_20210410T165940_037391_046811_38EF.zip   \n",
       "2   S1B_IW_SLC__1SDV_20210416T165829_20210416T165857_026495_0329CA_9CB3.zip   \n",
       "3   S1A_IW_SLC__1SDV_20210422T165913_20210422T165940_037566_046E25_93D0.zip   \n",
       "4   S1B_IW_SLC__1SDV_20210428T165830_20210428T165857_026670_032F67_4852.zip   \n",
       "..                                                                      ...   \n",
       "65  S1B_IW_SLC__1SDV_20211005T051743_20211005T051810_028996_0375C9_067D.zip   \n",
       "66  S1A_IW_SLC__1SDV_20211011T051825_20211011T051853_040067_04BE64_5A70.zip   \n",
       "67  S1B_IW_SLC__1SDV_20211017T051743_20211017T051810_029171_037B32_8EF0.zip   \n",
       "68  S1A_IW_SLC__1SDV_20211023T051825_20211023T051853_040242_04C47E_CF1D.zip   \n",
       "69  S1B_IW_SLC__1SDV_20211029T051743_20211029T051810_029346_038095_6DF0.zip   \n",
       "\n",
       "                                                                          SLC Pairs  \\\n",
       "0   (S1B_IW_SLC__1SDV_20210404T165829_20210404T165857_026320_032437_1DA7.zip, S1...   \n",
       "1   (S1A_IW_SLC__1SDV_20210410T165913_20210410T165940_037391_046811_38EF.zip, S1...   \n",
       "2   (S1B_IW_SLC__1SDV_20210416T165829_20210416T165857_026495_0329CA_9CB3.zip, S1...   \n",
       "3   (S1A_IW_SLC__1SDV_20210422T165913_20210422T165940_037566_046E25_93D0.zip, S1...   \n",
       "4   (S1B_IW_SLC__1SDV_20210428T165830_20210428T165857_026670_032F67_4852.zip, S1...   \n",
       "..                                                                              ...   \n",
       "65  (S1B_IW_SLC__1SDV_20211005T051743_20211005T051810_028996_0375C9_067D.zip, S1...   \n",
       "66  (S1A_IW_SLC__1SDV_20211011T051825_20211011T051853_040067_04BE64_5A70.zip, S1...   \n",
       "67  (S1B_IW_SLC__1SDV_20211017T051743_20211017T051810_029171_037B32_8EF0.zip, S1...   \n",
       "68  (S1A_IW_SLC__1SDV_20211023T051825_20211023T051853_040242_04C47E_CF1D.zip, S1...   \n",
       "69   (S1B_IW_SLC__1SDV_20211029T051743_20211029T051810_029346_038095_6DF0.zip, nan)   \n",
       "\n",
       "    Pair Timedelta  \n",
       "0  6 days 00:00:44  \n",
       "1  5 days 23:59:16  \n",
       "2  6 days 00:00:44  \n",
       "3  5 days 23:59:17  \n",
       "4  6 days 00:00:44  \n",
       "..             ...  \n",
       "65 6 days 00:00:42  \n",
       "66 5 days 23:59:18  \n",
       "67 6 days 00:00:42  \n",
       "68 5 days 23:59:18  \n",
       "69             NaT  \n",
       "\n",
       "[70 rows x 7 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# organise products as consecutive 6-day-pairs from same relative orbit\n",
    "\n",
    "# list all s1 products\n",
    "s1_files = glob.iglob(os.path.join(s1_data_path, \"*S1*.zip\"))\n",
    "s1_files = [os.path.basename(x) for x in list(s1_files)]\n",
    "\n",
    "# compile infos about s1 products into comprehensive df\n",
    "satellite, absolute_orbit, date_time, filename = ([] for i in range(4))\n",
    "\n",
    "for i in s1_files:\n",
    "    satellite.append(i.split(\"_\")[0])\n",
    "    absolute_orbit.append(i.split(\"_\")[7])\n",
    "    date_time.append(i.split(\"_\")[5])\n",
    "    filename.append(i)\n",
    "\n",
    "df_s1 = pd.DataFrame({\n",
    "    'Satellite' : satellite,\n",
    "    'Absolute Orbit': absolute_orbit,\n",
    "    'Time': date_time,\n",
    "    'Filename': filename\n",
    "})\n",
    "\n",
    "# conversion of orbit specifications based on filenames\n",
    "def convert_abs_rel_orbit(abs_orbit, satellite):\n",
    "    if satellite == \"S1A\":\n",
    "        rel_orbit = (int(abs_orbit) - 73) % 175 + 1\n",
    "    if satellite == \"S1B\":\n",
    "        rel_orbit = (int(abs_orbit) - 27) % 175 + 1\n",
    "    return rel_orbit\n",
    "\n",
    "df_s1.insert(2, \"Relative Orbit\", [convert_abs_rel_orbit(x,y) for x,y, in zip(df_s1[\"Absolute Orbit\"], df_s1[\"Satellite\"])])\n",
    "\n",
    "# arrange df to retrieve consecutive pairs\n",
    "df_s1[\"Time\"] = pd.to_datetime(df_s1[\"Time\"], format='%Y-%m-%dT%H:%M:%S')\n",
    "df_s1 = df_s1.sort_values([\"Relative Orbit\", \"Time\"]).reset_index(drop=True)\n",
    "S1_SLC_pairs = df_s1.groupby(\"Relative Orbit\")[\"Filename\"].transform(lambda x: zip(x, x.shift(-1)))\n",
    "S1_SLC_pairs_tdelta = df_s1.groupby(\"Relative Orbit\")[\"Time\"].transform(lambda x: x.shift(-1) - x)\n",
    "df_s1[\"SLC Pairs\"] = S1_SLC_pairs\n",
    "df_s1[\"Pair Timedelta\"] = S1_SLC_pairs_tdelta\n",
    "\n",
    "# check time deltas\n",
    "long_delta = df_s1[df_s1[\"Pair Timedelta\"] > pd.Timedelta(days=7)] \n",
    "print(f\"Warning: The timedelta between scenes is not equal, {len(long_delta)} scene pair is more than 6 days apart.\\n\")\n",
    "\n",
    "# print results\n",
    "df_s1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing (Coherence, Polarimetric Parameters, Backscatter Intensity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note that processing is done via snappy (see underlying .py scripts)\n",
    "# notebook calls .py scripts for each scene/scene pair\n",
    "# superior to direct implementation in notebook as memory blocked by SNAP is released after each cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product iteration 0 sucessfully generated (Thu Apr 21 10:13:42 2022, attempt 1).\n",
      "Product iteration 1 sucessfully generated (Thu Apr 21 10:14:55 2022, attempt 1).\n",
      "Product iteration 2 sucessfully generated (Thu Apr 21 10:16:00 2022, attempt 1).\n",
      "Product iteration 3 sucessfully generated (Thu Apr 21 10:17:24 2022, attempt 1).\n",
      "Product iteration 4 sucessfully generated (Thu Apr 21 10:18:32 2022, attempt 1).\n",
      "Product iteration 5 sucessfully generated (Thu Apr 21 10:19:57 2022, attempt 1).\n",
      "Product iteration 6 sucessfully generated (Thu Apr 21 10:21:12 2022, attempt 1).\n",
      "Product iteration 7 sucessfully generated (Thu Apr 21 10:22:24 2022, attempt 1).\n",
      "Product iteration 8 sucessfully generated (Thu Apr 21 10:23:30 2022, attempt 1).\n",
      "Product iteration 9 sucessfully generated (Thu Apr 21 10:24:38 2022, attempt 1).\n",
      "Product iteration 10 sucessfully generated (Thu Apr 21 10:25:49 2022, attempt 1).\n",
      "Product iteration 11 sucessfully generated (Thu Apr 21 10:27:04 2022, attempt 1).\n",
      "Product iteration 12 sucessfully generated (Thu Apr 21 10:28:26 2022, attempt 1).\n",
      "Product iteration 13 sucessfully generated (Thu Apr 21 10:29:34 2022, attempt 1).\n",
      "Product iteration 14 sucessfully generated (Thu Apr 21 10:30:43 2022, attempt 1).\n",
      "Product iteration 15 sucessfully generated (Thu Apr 21 10:31:54 2022, attempt 1).\n",
      "Product iteration 16 sucessfully generated (Thu Apr 21 10:33:03 2022, attempt 1).\n",
      "Product iteration 17 sucessfully generated (Thu Apr 21 10:34:17 2022, attempt 1).\n",
      "Product iteration 18 sucessfully generated (Thu Apr 21 10:35:31 2022, attempt 1).\n",
      "Product iteration 19 sucessfully generated (Thu Apr 21 10:36:46 2022, attempt 1).\n",
      "Product iteration 20 sucessfully generated (Thu Apr 21 10:38:01 2022, attempt 1).\n",
      "Product iteration 21 sucessfully generated (Thu Apr 21 10:39:14 2022, attempt 1).\n",
      "Product iteration 22 sucessfully generated (Thu Apr 21 10:40:27 2022, attempt 1).\n",
      "Product iteration 23 sucessfully generated (Thu Apr 21 10:41:41 2022, attempt 1).\n",
      "Product iteration 24 sucessfully generated (Thu Apr 21 10:43:06 2022, attempt 1).\n",
      "Product iteration 25 sucessfully generated (Thu Apr 21 10:44:19 2022, attempt 1).\n",
      "Product iteration 26 sucessfully generated (Thu Apr 21 10:45:29 2022, attempt 1).\n",
      "Product iteration 27 sucessfully generated (Thu Apr 21 10:46:43 2022, attempt 1).\n",
      "Product iteration 28 sucessfully generated (Thu Apr 21 10:48:08 2022, attempt 1).\n",
      "Product iteration 29 sucessfully generated (Thu Apr 21 10:49:21 2022, attempt 1).\n",
      "Product iteration 30 sucessfully generated (Thu Apr 21 10:50:35 2022, attempt 1).\n",
      "Product iteration 31 sucessfully generated (Thu Apr 21 10:51:49 2022, attempt 1).\n",
      "Product iteration 32 sucessfully generated (Thu Apr 21 10:53:01 2022, attempt 1).\n",
      "Product iteration 33 sucessfully generated (Thu Apr 21 10:54:16 2022, attempt 1).\n",
      "Product iteration 35 sucessfully generated (Thu Apr 21 10:55:59 2022, attempt 1).\n",
      "Product iteration 36 sucessfully generated (Thu Apr 21 10:57:20 2022, attempt 1).\n",
      "Product iteration 37 sucessfully generated (Thu Apr 21 10:58:36 2022, attempt 1).\n",
      "Product iteration 38 sucessfully generated (Thu Apr 21 10:59:52 2022, attempt 1).\n",
      "Product iteration 39 sucessfully generated (Thu Apr 21 11:01:09 2022, attempt 1).\n",
      "Product iteration 40 sucessfully generated (Thu Apr 21 11:02:37 2022, attempt 1).\n",
      "Product iteration 41 sucessfully generated (Thu Apr 21 11:04:09 2022, attempt 1).\n",
      "Product iteration 42 sucessfully generated (Thu Apr 21 11:05:51 2022, attempt 1).\n",
      "Product iteration 43 sucessfully generated (Thu Apr 21 11:07:28 2022, attempt 1).\n",
      "Product iteration 44 sucessfully generated (Thu Apr 21 11:08:49 2022, attempt 1).\n",
      "Product iteration 45 sucessfully generated (Thu Apr 21 11:10:09 2022, attempt 1).\n",
      "Product iteration 46 sucessfully generated (Thu Apr 21 11:11:29 2022, attempt 1).\n",
      "Product iteration 47 sucessfully generated (Thu Apr 21 11:13:06 2022, attempt 1).\n",
      "Product iteration 48 sucessfully generated (Thu Apr 21 11:14:26 2022, attempt 1).\n",
      "Product iteration 49 sucessfully generated (Thu Apr 21 11:15:59 2022, attempt 1).\n",
      "Product iteration 50 sucessfully generated (Thu Apr 21 11:17:18 2022, attempt 1).\n",
      "Product iteration 51 sucessfully generated (Thu Apr 21 11:18:41 2022, attempt 1).\n",
      "Product iteration 52 sucessfully generated (Thu Apr 21 11:20:06 2022, attempt 1).\n",
      "Product iteration 53 sucessfully generated (Thu Apr 21 11:21:41 2022, attempt 1).\n",
      "Product iteration 54 sucessfully generated (Thu Apr 21 11:22:58 2022, attempt 1).\n",
      "Product iteration 55 sucessfully generated (Thu Apr 21 11:24:06 2022, attempt 1).\n",
      "Product iteration 56 sucessfully generated (Thu Apr 21 11:25:38 2022, attempt 1).\n",
      "Product iteration 57 sucessfully generated (Thu Apr 21 11:27:00 2022, attempt 1).\n",
      "Product iteration 58 sucessfully generated (Thu Apr 21 11:28:21 2022, attempt 1).\n",
      "Product iteration 59 sucessfully generated (Thu Apr 21 11:29:43 2022, attempt 1).\n",
      "Product iteration 60 sucessfully generated (Thu Apr 21 11:31:11 2022, attempt 1).\n",
      "Product iteration 61 sucessfully generated (Thu Apr 21 11:32:47 2022, attempt 1).\n",
      "Product iteration 62 sucessfully generated (Thu Apr 21 11:34:05 2022, attempt 1).\n",
      "Product iteration 63 sucessfully generated (Thu Apr 21 11:35:26 2022, attempt 1).\n",
      "Product iteration 64 sucessfully generated (Thu Apr 21 11:36:54 2022, attempt 1).\n",
      "Product iteration 65 sucessfully generated (Thu Apr 21 11:38:15 2022, attempt 1).\n",
      "Product iteration 66 sucessfully generated (Thu Apr 21 11:39:35 2022, attempt 1).\n",
      "Product iteration 67 sucessfully generated (Thu Apr 21 11:40:42 2022, attempt 1).\n",
      "Product iteration 68 sucessfully generated (Thu Apr 21 11:42:11 2022, attempt 1).\n"
     ]
    }
   ],
   "source": [
    "# Coherence processing\n",
    "\n",
    "for idx, pair in enumerate(df_s1[\"SLC Pairs\"]):\n",
    "    # only proceed if pair is valid (no nan)\n",
    "    if pair[0] == pair[0] and pair[1] == pair[1]:  \n",
    "        file_1 = os.path.join(s1_data_path, pair[0])\n",
    "        file_2 = os.path.join(s1_data_path, pair[1])\n",
    "        # try workflow several times in case of failure (to account for java overload errors occuring from time to time)\n",
    "        attempts = 0\n",
    "        done = False\n",
    "        while not done and attempts < 2:\n",
    "            try:\n",
    "                pipeline_out = subprocess.check_output([python_kernel, 'coherence_processing.py', file_1, file_2], stderr=subprocess.STDOUT)\n",
    "                print(f\"Product iteration {idx} sucessfully generated ({time.ctime()}, attempt {attempts+1}).\")\n",
    "                done = True\n",
    "            except:\n",
    "                attempts += 1\n",
    "                if attempts == 2:\n",
    "                    print(f\"Warning: Product in iteration {idx} could not be generated despite several attempts.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intensity processing\n",
    "\n",
    "# for idx, s1_file in enumerate(df_s1[\"Filename\"]):\n",
    "for idx, s1_file in enumerate(df_s1.sort_values(\"Time\").iloc[:4,][\"Filename\"]):\n",
    "    file = os.path.join(s1_data_path, s1_file)\n",
    "    # try workflow several times in case of failure (to account for java overload errors occuring from time to time)\n",
    "    attempts = 0\n",
    "    done = False\n",
    "    while not done and attempts < 3:\n",
    "        try:\n",
    "            pipeline_out = subprocess.check_output([python_kernel, 'intensity_processing_incl_incidence_info.py', file], stderr=subprocess.STDOUT)\n",
    "            print(f\"Product iteration {idx} sucessfully generated ({time.ctime()}, attempt {attempts+1}).\")\n",
    "            done = True\n",
    "        except:\n",
    "            attempts += 1\n",
    "            if attempts == 3:\n",
    "                print(f\"Warning: Product in iteration {idx} could not be generated despite several attempts.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get GR pixel spacing for S1 IW scene & subswaths \n",
    "with open(\n",
    "    \"C://Users/felix/Desktop/Adv_Rs_project/01_data_raw/test_area_processing.txt\",\n",
    "    \"r\",\n",
    ") as f:\n",
    "    aoi_wkt = f.read()\n",
    "\n",
    "file_1 = os.path.join(s1_data_path, df_s1[\"Filename\"][0])\n",
    "read_ = snappy.ProductIO.readProduct(file_1)\n",
    "\n",
    "params = snappy.HashMap()\n",
    "params.put(\"selectedPolarisations\", \"VV, VH\")\n",
    "params.put(\"subswath\", \"IW1\")\n",
    "    \n",
    "split_1 = snappy.GPF.createProduct(\"TOPSAR-Split\", params, read_)\n",
    "\n",
    "params = snappy.HashMap()\n",
    "params.put(\"selectedPolarisations\", \"VV, VH\")\n",
    "params.put(\"subswath\", \"IW2\")\n",
    "    \n",
    "split_2 = snappy.GPF.createProduct(\"TOPSAR-Split\", params, read_)\n",
    "\n",
    "params = snappy.HashMap()\n",
    "params.put(\"selectedPolarisations\", \"VV, VH\")\n",
    "params.put(\"subswath\", \"IW3\")\n",
    "    \n",
    "split_3 = snappy.GPF.createProduct(\"TOPSAR-Split\", params, read_)\n",
    "\n",
    "import numpy as np\n",
    "import snappy\n",
    "from geographiclib.geodesic import Geodesic\n",
    "\n",
    "def calc_pixel_size(prod):\n",
    "    corner_top_left = prod.getSceneGeoCoding().getGeoPos(snappy.PixelPos(0,0), None)\n",
    "    corner_bottom_left = prod.getSceneGeoCoding().getGeoPos(snappy.PixelPos(0, prod.getSceneRasterHeight()), None)\n",
    "    corner_top_right = prod.getSceneGeoCoding().getGeoPos(snappy.PixelPos(prod.getSceneRasterWidth(), 0), None)\n",
    "    height_range_m = Geodesic.WGS84.Inverse(corner_top_left.getLat(), corner_top_left.getLon(), corner_bottom_left.getLat(), corner_bottom_left.getLon())[\"s12\"]\n",
    "    width_range_m = Geodesic.WGS84.Inverse(corner_top_left.getLat(), corner_top_left.getLon(), corner_top_right.getLat(), corner_top_right.getLon())[\"s12\"]\n",
    "    height_n_pixels = prod.getSceneRasterHeight()\n",
    "    width_n_pixels = prod.getSceneRasterWidth()\n",
    "    mean_pixel_size = (round(height_range_m/height_n_pixels,2), round(width_range_m/width_n_pixels,2))\n",
    "    mean_pixel_size\n",
    "    return mean_pixel_size\n",
    "\n",
    "calc_pixel_size(read_) # read_1 corresponds to snappy.ProductIO.readProduct(file_1)\n",
    "calc_pixel_size(split_1) # split_1 is generated by snappy.GPF.createProduct(\"TOPSAR-Split\", params, read_1) with IW1\n",
    "calc_pixel_size(split_2) # analogous to split_1 with IW2\n",
    "calc_pixel_size(split_3) # analogous to split_1 with IW3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results experimental tests on parameters coherence\n",
    "* v1 with rg 10, low res dem (srtm 3sec)\n",
    "* v2 with rg 20, high res dem (srtm 1sec hgt) -> leads to java heap space/DataBuffer error from time to time\n",
    "* v3 analogous with low res dem\n",
    "* v4 with rg 20, az 4 (explicitly), low res\n",
    "* v5 with rg 20, no az spec, low res\n",
    "* v6 with rg 20, no az spec, no terrain geocoding to retrieve pixel size\n",
    "* v9 with rg 11, az 3 as calcualted manually to obtain pixels of approx. 37.5m ~ 37.5m\n",
    "* v10 with rg 11, az 3 & DOM Copernicus for heights\n",
    "* v11 with rg 11, az 3 & multilooking for sqaure pixels\n",
    "* v12 with rg 11, az 3 & no interpolation (simple nearest neighbour)\n",
    "\n",
    "* specification of az & range necessary to obtain square pixels\n",
    "* garbage collection working or not?\n",
    "* processing times > 30 min not feasible\n",
    "* writing to external disk sometimes with problems (write directly to local ssd)\n",
    "* GPF methods in writing faster than ProductIO\n",
    "* stick with DGM as DOM not really better since resolution comparable (30m)\n",
    "* use nearest neighbour interpolation for terrain correction to avoid interpolation of nan coherence values & avoid unnecessary reduction of spatial resolution\n",
    "* avoid multilooking as unnecessary reduction of spatial resolution (as coherence is already calculated using a larger window)\n",
    "* note that multilooking would only be possible after coherence estimation (as phases get incoherently averaged)\n",
    "* further enhancements tbd: Enhanced Spectral Diversity\n",
    "* why is no thermal noise removal applied in the literature, only the calculation of noise stemming from systems properties is done afterwards\n",
    "* https://sentinel.esa.int/documents/247904/2142675/Thermal-Denoising-of-Products-Generated-by-Sentinel-1-IPF"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "74f165375eeadae01a71b7c93b6e01cd78bbdc52dd300a115d11bb6e3f4ead51"
  },
  "kernelspec": {
   "display_name": "Python 3.6.0 ('snap')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
